# VisionSlide ğŸ¥â¡ï¸ğŸ“Š

````markdown
**VisionSlide** is an experimental project that allows you to **control Microsoft PowerPoint presentations using computer vision and hand gestures**.  
No more clickers â€“ just your camera, your hands, and AI-powered interaction. ğŸš€

---

## âœ¨ Features (MVP)
- Move to **next slide** with a hand gesture
- Move to **previous slide** with a hand gesture  
- Close PowerPoint with a specific gesture
- Real-time hand tracking and gesture recognition
- (Planned) Use gestures to highlight or point during a presentation

---

## ğŸ› ï¸ Tech Stack
- **Python 3.9+**
- [OpenCV](https://opencv.org/) â†’ video capture and image processing
- [MediaPipe](https://developers.google.com/mediapipe) â†’ hand & gesture detection
- [PyAutoGUI](https://pyautogui.readthedocs.io/en/latest/) â†’ simulate keyboard input for PowerPoint
- [NumPy](https://numpy.org/) â†’ mathematical operations

---

## ğŸš€ Getting Started

### Prerequisites
- Python 3.9 or higher
- A webcam
- Microsoft PowerPoint installed
- Windows/macOS/Linux compatible

### Installation
1. Clone the repository:
   ```bash
   git clone https://github.com/your-username/visionslide.git
   cd visionslide
````

2. Install dependencies:

   ```bash
   pip install -r requirements.txt
   ```

3. Run the prototype:

   ```bash
   python app.py
   ```

### Usage

1. Open a PowerPoint presentation
2. Launch VisionSlide
3. Position yourself in front of your camera
4. Use the following gestures:

   * **Next slide** â†’ Point right with index finger
   * **Previous slide** â†’ Point left with index finger
   * **Exit** â†’ Close your fist and hold for 2 seconds

---

## ğŸ“ Project Structure

```
visionslide/
â”œâ”€â”€ app.py                  # Main application entry point
â”œâ”€â”€ requirements.txt        # Project dependencies
â”œâ”€â”€ README.md               # Project documentation
â”œâ”€â”€ setup.py                # Packaging configuration
â”‚
â”œâ”€â”€ visionslide/            # Core package
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ camera/             # Camera management
â”‚   â”‚   â””â”€â”€ camera_stream.py
â”‚   â”œâ”€â”€ gestures/           # Hand gesture detection & mapping
â”‚   â”‚   â”œâ”€â”€ gesture_detector.py
â”‚   â”‚   â””â”€â”€ gesture_mapping.py
â”‚   â”œâ”€â”€ controls/           # Presentation & OS controllers
â”‚   â”‚   â”œâ”€â”€ ppt_controller.py
â”‚   â”‚   â”œâ”€â”€ os_controller.py
â”‚   â”‚   â””â”€â”€ zoom_controller.py
â”‚   â””â”€â”€ utils/              # Utility functions (logging, helpers)
â”‚       â”œâ”€â”€ logger.py
â”‚       â””â”€â”€ helpers.py
â”‚
â”œâ”€â”€ tests/                  # Unit tests
â”‚   â”œâ”€â”€ test_camera.py
â”‚   â”œâ”€â”€ test_gestures.py
â”‚   â””â”€â”€ test_controls.py
â”‚
â”œâ”€â”€ assets/                 # Images and demo files
â”‚   â””â”€â”€ demo.gif            # Demo video (coming soon)
â”‚
â””â”€â”€ docs/                   # Documentation
    â”œâ”€â”€ architecture.md
    â””â”€â”€ roadmap.md
```

---

## ğŸ¯ Roadmap

* [x] Detect basic gestures (next/previous slide)
* [ ] Add gesture to exit PowerPoint
* [ ] Add gesture to activate a laser pointer
* [ ] Build a GUI to customize gestures
* [ ] Integration with Zoom/Teams presentations
* [ ] Support for Google Slides and other presentation software
* [ ] Voice command integration
* [ ] Multi-hand gesture combinations

---

## ğŸ”§ Configuration

Customize gesture sensitivity and controls in `config.py`:

```python
# Gesture sensitivity (0.1 - 1.0)
GESTURE_CONFIDENCE = 0.7

# Gesture hold time (seconds)
GESTURE_HOLD_TIME = 1.5

# Camera settings
CAMERA_INDEX = 0
FRAME_WIDTH = 640
FRAME_HEIGHT = 480
```

---

## ğŸ¤ Contributing

Contributions are welcome!
To contribute:

1. Fork the project
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ¬ Demo

A demo video will be added once the first stable prototype is ready.

![Demo GIF placeholder](assets/demo.gif)
*Demo coming soon...*

---

## ğŸ› Known Issues

* Lighting conditions may affect gesture recognition accuracy
* Currently optimized for single-user presentations
* MediaPipe model loading may take time on first run

---

## ğŸ’¡ Vision

VisionSlide started as an idea to make presentations more **interactive and intuitive**.
The long-term vision is to **integrate gesture-based control into Microsoft Office tools** and boost productivity in both live and online presentations.

Future possibilities include AR/VR headset integration, multi-user gesture control, and AI-powered presentation assistance.

---

## ğŸ‘¤ Author

**Nelson (Nelsbrowser)** â€“ Passionate about AI, computer vision, and building innovative productivity tools.

* GitHub: [@Nels-G](https://github.com/Nels-G)
* Email: [nelsgalley@gmail.com](mailto:nelsgalley@gmail.com)

---

## ğŸ™ Acknowledgments

* [MediaPipe](https://developers.google.com/mediapipe) for excellent hand tracking models
* [OpenCV](https://opencv.org/) community for computer vision tools
* Microsoft PowerPoint for inspiration

---

## â­ Star this repo

If you find this project useful, please consider giving it a star â­ â€“ it helps others discover the project!

```

---

ğŸ‘‰ Ce README correspond maintenant exactement Ã  ton **architecture Ã©volutive**, sans contradiction.  

Veux-tu que je te prÃ©pare aussi un **requirements.txt minimal** (OpenCV, MediaPipe, PyAutoGUI, NumPy) pour que ton projet soit exÃ©cutable dÃ¨s le clonage ?
```

